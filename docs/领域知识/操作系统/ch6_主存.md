# 主存

!!!note 课程的理论讲的是普适情况，实际取决于OS和体系结构等的设计

## 背景

> 此处不区分主存和内存这两个称呼

### 内存发展史

略，只需要知道DRAM、SRAM和ROM分别是什么，以及内存的发展速度赶不上处理器

### 内存的作用

- 程序必须被加载到内存，并且被放入线程才能执行，前面也说过线程本质是active的内存
- 主存和寄存器只能够被CPU直接访问
- 访问寄存器只需要一个时钟周期（或者更少），访问主存需要多个时钟周期，所以主存和寄存器之间存在Cache
- 内存需要被保护来确保操作正确

> 内存层级也是老生常谈了，此处略

### 编译与执行

编译与执行的过程中会涉及如下软件：

- 编译器(compiler)是一个计算机程序，它能够将源代码转化为另一种计算机语言（往往是二进制形式，称作目标代码）
- 链接器(linker)是一个程序，它能够加载一个或多个由编译器生成的目标，把它们整合进一个可执行文件
- 装载器(loader)加载`.exe`文件到内存中执行

存在三种地址：

1. 符号地址(Symbolic Address)：源程序中的地址通常是符号地址，比如变量
2. 可重定位地址(Relocatable Address)：编译器通常绑定它们的符号地址到可重定位地址（比如距离这个模块开头14byte）
3. 绝对地址(Absolute Address)：连接器或者装载器将可重定位地址绑定到绝对地址（比如0x1000）

代码和数据绑定到内存地址可以在三个不同阶段发生：

1. 编译时刻(Compile time)：编译出来的代码已经是绝对地址，如果地址变化必须重新编译
2. 装入时刻(Load time)：如果在编译时刻代码地址未知，必须生成可重定位代码
3. 执行时刻(Execution time)：绑定被推迟到了执行时，绑定的地址可以在执行时变动，需要硬件的支持

### 逻辑地址和物理地址

基址(base)寄存器和限长(limit)寄存器定义了逻辑地址空间：

<center><img src="images/ch6/base_limit.png" width=200></center>

- 逻辑地址空间指的是CPU生成的空间
- 物理地址空间指的是MMU能看到的地址

逻辑地址和物理地址对于编译时和装载时绑定是相同的，对于执行时绑定是不同的。

### MMU

MMU(Memoey Management Unit)是负责映射虚拟地址到物理地址的硬件设备，在MMU机制下，在访问内存前，可重定位寄存器的值会被添加到每个由用户进程生成的地址上（这是最简单的虚拟内存机制，实际没有这么简单）。

<center><img src="images/ch6/relocation_reg.png" width=300></center>

用户进程只能处理逻辑地址，它永远不可能看见真实的物理地址。

### 动态装载/链接

动态装载是指程序只有在被调用时才会被装载，这样可以更好利用内存，不使用的程序不会被装载，在有大量代码低频出现的场景下非常有用，并且不需要操作系统特别支持。

动态链接是指链接延迟到了执行时，一小份代码（称作stub）被用来装载 memory-resident library routine，本质是将stub的地址替换为了routine的地址，从而去执行routine，OS需要检验routine是否在程序的内存地址中。动态链接的好处有：

- 节省主存空间
- 减少可执行文件大小
- 不需要重新链接到新库

动态链接和共享库需要操作系统的支持，共享库在Windows中是`dll`文件

## 内存管理

### 内存保护

主存通常被两部分使用，即OS和用户进程，可以将OS放在低地址或者高地址，很多OS，包括Windows和Linux选择放在高地址。

需要防止进程访问它不拥有的地址，重定位寄存器被用来保护用户进程相互之间不干扰，以及不能改变OS的代码和数据。

- 重定位寄存器中包含了最小物理地址
- 限长寄存器包含了逻辑地址的范围，所有逻辑地址都小于限长寄存器的值
- MMU通过添加重定位寄存器中的值动态映射逻辑地址

重定位寄存器提供了一种高效的机制动态改变OS的大小。

OS运行在内核态，被赋予了对OS内存和用户内存不受限的访问权限。

<center><img src="images/ch6/limit_relocation.png" width=400></center>

!!!question 为什么不用软件实现limit reg和relocation reg？
    因为访问内存是非常普遍的操作，使用软件效率太低，而且软件不够安全。

### 连续分配

连续内存分配(Contiguous memory allocation)：每个进程都被包含在了单一内存段中，紧邻的另一内存段包含的是下一个进程。具体分为：

- 单一连续分配(Single Cotinous Allocation)：内存分为系统区和用户区，用户区每次只调入一道程序运行，也就是说没有并发
- 多分区分配(Multiple-partition allocation)：将内存划分为若干个连续区域，称为分区，每个分区只能存放一个进程：
  - 固定分区(fixed partition)
  - 动态分区(dynamic partition)

固定分区就是把每个分区的大小提前划分好

<center><img src="images/ch6/fixed_partition.png" width=150></center>

动态分区是在程序装入内存时把可用内存“切出”一个连续的区域分配给该进程，且分区大小正好适合进程的需要（实际不一定是刚刚好，一般会稍微多分配点）：

- 空洞(hole)：可用的内存区块，不同大小的空洞散布在内存中
- 当有进程抵达时，它会被分配足够容纳它的内存
- OS维护已分配的分区和空闲分区(hole)的信息

<center><img src="images/ch6/dynamic_partition.png" width=400></center>

上面说了hole是散布在内存中的，所以需要选择一块合适的给抵达的进程，一般情况OS维护的空洞信息可以看做是一个线性表，有三种选择算法（在ads装箱问题中学过，此处不赘述）：

1. First-fit
2. Best-fit
3. Worst-fit

此外，还可以选择优化所维护空洞信息的结构，这部分又很像数据库中的索引，总之要加速查找：

1. 快速适应算法：将空闲分区按大小进行分类，设置索引表项，每一个空闲分区类型对应一项，挂成链（把原来的一根变成多根），需要查找时直接查找索引，然后取出第一块进行分配。这个在内存池的实现中见过，好像数据库中也有类似的思想。
2. 伙伴系统：每个空闲分区必须是2的n次幂字节，对进程占用的空间n计算一个i值使$2^i>n $，从剩余空闲分区找最适合的，若无则逐层拆分，释放时逐层合并。OS lab4 中给出了伙伴系统的实现。
3. 哈希算法：根据空闲分区链表的分布规律，建立哈希函数，构建一张以空闲分区大小为关键字的哈希表，根据所需空间大小计算得到哈希表的位置。这个类似于数据库中的哈希索引。

### 碎片

内存中可能都存在一些细小的空洞，无法分配给任何进程，这造成了内存的浪费：

- 外部碎片：存在于不同的分区间，这些碎片的总和可能可以满足一个请求，但是不连续。50-percent rule：分配N个块，另外0.5N个块会被浪费
- 内部碎片：分配的内存可能比请求的内存稍大，多出来的那部分有可能实际未被使用

减少外部碎片可以通过整合(compaction)，将所有碎片集中至一处，比如将所有进程移动至内存空间的一侧，空洞移动至另一侧，不过整合只有在执行时刻绑定地址才适用。移动进程的地址会导致I/O问题，可以选择锁住正在进行I/O的进程，也可以选择仅在OS buffer中进行I/O

实际还有一个解决外部碎片的方案是非连续分配

### 分页

!!!tip 分页思想的来源
    分页显然不是凭空造出来的方案，它是基于：
    - 非连续分配：分配给一个进程的内存可以物理上不连续，以此来减少外部碎片，提高内存利用率
    - 虚拟内存：进程看到的内存最好是连续的，这样可以简化进程执行的逻辑，于是选择将不连续的物理地址映射为连续的逻辑地址
    - 查找效率：访问的逻辑地址一定需要被翻译成物理地址，如果映射非常随机，那么翻译的开销会很大，所以一次要映射一小段连续内存，也就是分页

